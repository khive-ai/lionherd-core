{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Service Lifecycle Management with TaskGroups\n",
    "\n",
    "**Category**: Concurrency\n",
    "**Difficulty**: Advanced\n",
    "**Time**: 25-35 minutes\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Building production services often requires coordinating multiple components with complex dependencies. Consider an HTTP API service that needs:\n",
    "\n",
    "- A database connection pool that must be ready before anything else\n",
    "- A cache layer that depends on the database\n",
    "- An HTTP server that depends on both database and cache\n",
    "- Background workers processing tasks from a queue\n",
    "- A health monitoring system that checks all components\n",
    "\n",
    "The challenge isn't just running these concurrently - it's managing their lifecycle: **initialization order**, **readiness signaling**, **health monitoring**, and **graceful shutdown**. If the database takes 2 seconds to connect, the API shouldn't start serving requests. If a component fails health checks, the service should shut down cleanly.\n",
    "\n",
    "Traditional approaches like spawning independent tasks lead to race conditions: the API starts before the database is ready, health checks run before components initialize, or shutdown leaves orphaned background workers.\n",
    "\n",
    "**Why This Matters**:\n",
    "- **Correctness**: Components accessing uninitialized dependencies cause crashes or data corruption\n",
    "- **Observability**: Without coordinated health checks, you can't tell if the service is actually ready\n",
    "- **Reliability**: Uncoordinated shutdown leaves connections open, jobs incomplete, or resources leaked\n",
    "\n",
    "**What You'll Build**:\n",
    "A production-ready service manager using lionherd-core's `create_task_group()`, `task_status.started()`, and Event coordination that manages multi-component initialization, dependency ordering, health monitoring, and graceful shutdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Prior Knowledge**:\n",
    "- Python async/await fundamentals (asyncio basics)\n",
    "- Understanding of context managers (async with)\n",
    "- Structured concurrency concepts (task groups, cancellation)\n",
    "\n",
    "**Required Packages**:\n",
    "```bash\n",
    "pip install lionherd-core  # >=1.0.0a3\n",
    "```\n",
    "\n",
    "**Optional Reading**:\n",
    "- [API Reference: Task Groups](../../docs/api/libs/concurrency/task.md)\n",
    "- [Reference Notebook: Task Groups](../references/concurrency_task.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from typing import Any\n",
    "\n",
    "# Third-party\n",
    "import anyio\n",
    "from anyio.abc import TaskStatus\n",
    "\n",
    "# lionherd-core\n",
    "from lionherd_core.libs.concurrency import (\n",
    "    Event,\n",
    "    create_task_group,\n",
    "    get_cancelled_exc_class,\n",
    "    sleep,\n",
    ")\n",
    "\n",
    "# Configure logging for examples\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s.%(msecs)03d] %(name)s: %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Overview\n",
    "\n",
    "We'll implement a service manager using structured concurrency that handles the complete lifecycle:\n",
    "\n",
    "1. **Initialization Protocol**: Services signal readiness via `task_status.started()`\n",
    "2. **Dependency Ordering**: Parent waits for dependencies before starting dependents\n",
    "3. **Event Coordination**: Health checks use Events to signal between components\n",
    "4. **Graceful Shutdown**: Cancel scope triggers coordinated cleanup\n",
    "\n",
    "**Key lionherd-core Components**:\n",
    "- `create_task_group()`: Structured concurrency context ensuring all tasks complete\n",
    "- `TaskGroup.start()`: Wait for service initialization\n",
    "- `TaskGroup.start_soon()`: Spawn background tasks\n",
    "- `Event`: Signal coordination between tasks\n",
    "- `cancel_scope`: Timeout and graceful shutdown\n",
    "\n",
    "**Flow**:\n",
    "```\n",
    "Startup:\n",
    "  Database ‚Üí started() ‚Üí Cache ‚Üí started() ‚Üí API ‚Üí started()\n",
    "                                    ‚Üì\n",
    "                         Health Monitor (Events)\n",
    "                                    ‚Üì\n",
    "                              Workers (Queue)\n",
    "\n",
    "Shutdown:\n",
    "  cancel_scope.cancel() ‚Üí All tasks receive cancellation\n",
    "                       ‚Üí Graceful cleanup in each\n",
    "                       ‚Üí TaskGroup waits for all\n",
    "                       ‚Üí Exit\n",
    "```\n",
    "\n",
    "**Expected Outcome**: Services start in correct order, health monitoring confirms readiness, shutdown is clean and coordinated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Database] Starting...\n",
      "[Database] Running\n",
      "‚úì Database ready\n",
      "[Database] Stopped\n",
      "‚úì Lifecycle complete\n"
     ]
    }
   ],
   "source": [
    "# Quick Start: Service Lifecycle in 30 Seconds\n",
    "\n",
    "\n",
    "async def service(name: str, events: Event, *, task_status: TaskStatus = anyio.TASK_STATUS_IGNORED):\n",
    "    \"\"\"Minimal service with lifecycle.\"\"\"\n",
    "    print(f\"[{name}] Starting...\")\n",
    "    await sleep(0.1)  # Simulate startup\n",
    "\n",
    "    task_status.started(f\"{name} ready\")\n",
    "    events.set()  # Signal ready\n",
    "    print(f\"[{name}] Running\")\n",
    "\n",
    "    await events.wait()  # Wait for shutdown\n",
    "    print(f\"[{name}] Stopped\")\n",
    "\n",
    "# Try it:\n",
    "shutdown = Event()\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start service and wait for ready\n",
    "    status = await tg.start(service, \"Database\", shutdown)\n",
    "    print(f\"‚úì {status}\")\n",
    "\n",
    "    await sleep(0.2)\n",
    "\n",
    "    # Trigger shutdown\n",
    "    shutdown.set()\n",
    "\n",
    "print(\"‚úì Lifecycle complete\")\n",
    "\n",
    "# üëá Now read below to understand coordinated multi-service lifecycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define Service States and Event Coordination\n",
    "\n",
    "Before implementing services, we need clear state definitions and event signaling mechanisms. Services transition through states (Initializing ‚Üí Running ‚Üí Stopping ‚Üí Stopped), and components coordinate via Events.\n",
    "\n",
    "**Why Events**: Events provide thread-safe signaling between tasks. A health monitor can wait for a \"database_ready\" event before checking database health, avoiding race conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Database: initializing\n",
      "Events ready: False\n",
      "Events shutdown: False\n"
     ]
    }
   ],
   "source": [
    "class ServiceState(Enum):\n",
    "    \"\"\"Service lifecycle states.\"\"\"\n",
    "    INITIALIZING = \"initializing\"\n",
    "    RUNNING = \"running\"\n",
    "    STOPPING = \"stopping\"\n",
    "    STOPPED = \"stopped\"\n",
    "    FAILED = \"failed\"\n",
    "\n",
    "@dataclass\n",
    "class ServiceStatus:\n",
    "    \"\"\"Service status with state and metadata.\"\"\"\n",
    "    name: str\n",
    "    state: ServiceState\n",
    "    details: dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.name}: {self.state.value}\"\n",
    "\n",
    "@dataclass\n",
    "class ServiceEvents:\n",
    "    \"\"\"Coordination events for service lifecycle.\"\"\"\n",
    "    ready: Event = field(default_factory=Event)\n",
    "    shutdown: Event = field(default_factory=Event)\n",
    "    health_check: Event = field(default_factory=Event)\n",
    "\n",
    "# Example usage\n",
    "status = ServiceStatus(name=\"Database\", state=ServiceState.INITIALIZING)\n",
    "events = ServiceEvents()\n",
    "\n",
    "print(f\"Status: {status}\")\n",
    "print(f\"Events ready: {events.ready.is_set()}\")\n",
    "print(f\"Events shutdown: {events.shutdown.is_set()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- `ServiceState` enum ensures type safety and clear transitions\n",
    "- `ServiceEvents` groups related events (ready, shutdown, health_check) for easier management\n",
    "- Events are created once and shared across tasks - don't create new Event instances for coordination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Basic Service with Lifecycle\n",
    "\n",
    "A service needs initialization, operation, and cleanup phases. The `task_status.started()` protocol signals when initialization completes, allowing dependents to proceed.\n",
    "\n",
    "**Why task_status.started()**: Without it, parent tasks can't distinguish \"still initializing\" from \"ready\". Using `start()` instead of `start_soon()` provides synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:26:07.238] __main__: [Database] Initializing connection pool...\n",
      "[23:26:07.439] __main__: [Database] Ready (10 connections)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Service started: Database: running\n",
      "  Details: {'connections': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:26:07.743] __main__: [Database] Shutting down...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Service lifecycle complete\n"
     ]
    }
   ],
   "source": [
    "async def database_service(\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Simulated database service with lifecycle management.\"\"\"\n",
    "    name = \"Database\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        # Initialize (simulate connection pool setup)\n",
    "        logger.info(f\"[{name}] Initializing connection pool...\")\n",
    "        await sleep(0.2)  # Simulate startup time\n",
    "\n",
    "        # Signal ready\n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"connections\"] = 10\n",
    "        task_status.started(status)\n",
    "        logger.info(f\"[{name}] Ready (10 connections)\")\n",
    "\n",
    "        # Run (keep-alive, health checks)\n",
    "        while True:\n",
    "            await sleep(1.0)  # Simulate periodic maintenance\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        # Graceful shutdown\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.1)  # Simulate cleanup (close connections)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        status.state = ServiceState.FAILED\n",
    "        logger.error(f\"[{name}] Failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Test the service lifecycle\n",
    "async with create_task_group() as tg:\n",
    "    # Wait for database to initialize\n",
    "    status = await tg.start(database_service)\n",
    "    print(f\"\\n‚úì Service started: {status}\")\n",
    "    print(f\"  Details: {status.details}\")\n",
    "\n",
    "    # Let it run briefly\n",
    "    await sleep(0.3)\n",
    "\n",
    "    # Trigger shutdown\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n‚úì Service lifecycle complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- `task_status.started(status)` returns ServiceStatus to caller - useful for passing connection info\n",
    "- Cancellation triggers graceful shutdown - always catch `get_cancelled_exc_class()` for cleanup\n",
    "- State transitions (INITIALIZING ‚Üí RUNNING ‚Üí STOPPING ‚Üí STOPPED) provide observability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add Multi-Service Coordination with Dependencies\n",
    "\n",
    "Real services have dependencies: cache needs database, API needs both. We use `await tg.start()` sequentially to enforce ordering.\n",
    "\n",
    "**Why Sequential start()**: Each `await tg.start()` blocks until `task_status.started()` is called, ensuring dependencies are ready before dependents start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:26:07.758] __main__: [Database] Initializing connection pool...\n",
      "[23:26:07.960] __main__: [Database] Ready (10 connections)\n",
      "[23:26:07.962] __main__: [Cache] Connecting to Database...\n",
      "[23:26:08.114] __main__: [Cache] Ready (cache_size: 100MB)\n",
      "[23:26:08.116] __main__: [API] Starting HTTP server (port: 8000)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Database: running\n",
      "‚úì Cache: running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:26:08.219] __main__: [API] Ready (port: 8000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì API: running\n",
      "  Dependencies: ['Database', 'Cache']\n",
      "\n",
      "‚úì All services ready\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:26:08.524] __main__: [Database] Shutting down...\n",
      "[23:26:08.525] __main__: [API] Shutting down...\n",
      "[23:26:08.525] __main__: [Cache] Shutting down...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating shutdown...\n",
      "\n",
      "\n",
      "‚úì Coordinated lifecycle complete\n"
     ]
    }
   ],
   "source": [
    "async def cache_service(\n",
    "    db_status: ServiceStatus,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Cache service that depends on database.\"\"\"\n",
    "    name = \"Cache\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        # Use database connection from db_status\n",
    "        logger.info(f\"[{name}] Connecting to {db_status.name}...\")\n",
    "        await sleep(0.15)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"cache_size\"] = \"100MB\"\n",
    "        task_status.started(status)\n",
    "        logger.info(f\"[{name}] Ready (cache_size: 100MB)\")\n",
    "\n",
    "        while True:\n",
    "            await sleep(1.0)\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "async def api_service(\n",
    "    db_status: ServiceStatus,\n",
    "    cache_status: ServiceStatus,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"HTTP API service that depends on database and cache.\"\"\"\n",
    "    name = \"API\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"[{name}] Starting HTTP server (port: 8000)...\")\n",
    "        await sleep(0.1)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"port\"] = 8000\n",
    "        status.details[\"dependencies\"] = [db_status.name, cache_status.name]\n",
    "        task_status.started(status)\n",
    "        logger.info(f\"[{name}] Ready (port: 8000)\")\n",
    "\n",
    "        while True:\n",
    "            await sleep(1.0)\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "# Test coordinated startup\n",
    "async with create_task_group() as tg:\n",
    "    # Start in dependency order\n",
    "    db_status = await tg.start(database_service)\n",
    "    print(f\"‚úì {db_status}\")\n",
    "\n",
    "    cache_status = await tg.start(cache_service, db_status)\n",
    "    print(f\"‚úì {cache_status}\")\n",
    "\n",
    "    api_status = await tg.start(api_service, db_status, cache_status)\n",
    "    print(f\"‚úì {api_status}\")\n",
    "    print(f\"  Dependencies: {api_status.details['dependencies']}\")\n",
    "\n",
    "    # All services running\n",
    "    print(\"\\n‚úì All services ready\\n\")\n",
    "    await sleep(0.3)\n",
    "\n",
    "    # Coordinated shutdown\n",
    "    print(\"Initiating shutdown...\\n\")\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n‚úì Coordinated lifecycle complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Passing `db_status` to `cache_service` provides connection info (not just signaling)\n",
    "- Services start sequentially but run concurrently after initialization\n",
    "- Shutdown happens in reverse (cancel propagates to all tasks simultaneously)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Add Health Monitoring with Event Signaling\n",
    "\n",
    "Health monitors need to coordinate with services: wait for services to be ready, check them periodically, signal failures.\n",
    "\n",
    "**Why Events**: Health monitor waits for `ready` event before checking. Services set events after initialization. This avoids polling or sleep-based coordination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:26:08.541] __main__: [HealthMonitor(TestService)] Waiting for TestService ready...\n",
      "[23:26:08.542] __main__: [TestService] Initializing...\n",
      "[23:26:08.693] __main__: [TestService] Ready (ready event set)\n",
      "[23:26:08.695] __main__: [HealthMonitor(TestService)] TestService is ready, starting checks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì TestService: running\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:26:08.897] __main__: [HealthMonitor(TestService)] Health check #1: OK\n",
      "[23:26:09.099] __main__: [HealthMonitor(TestService)] Health check #2: OK\n",
      "[23:26:09.198] __main__: [HealthMonitor(TestService)] Stopped (performed 2 checks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initiating shutdown...\n",
      "\n",
      "\n",
      "‚úì Health monitoring complete\n"
     ]
    }
   ],
   "source": [
    "async def monitored_service(\n",
    "    name: str,\n",
    "    startup_time: float,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Service with health monitoring integration.\"\"\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"[{name}] Initializing...\")\n",
    "        await sleep(startup_time)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        task_status.started(status)\n",
    "        events.ready.set()  # Signal health monitor\n",
    "        logger.info(f\"[{name}] Ready (ready event set)\")\n",
    "\n",
    "        # Wait for shutdown signal\n",
    "        await events.shutdown.wait()\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "async def health_monitor(\n",
    "    service_name: str,\n",
    "    events: ServiceEvents,\n",
    ") -> None:\n",
    "    \"\"\"Health monitoring task that waits for service readiness.\"\"\"\n",
    "    monitor_name = f\"HealthMonitor({service_name})\"\n",
    "\n",
    "    try:\n",
    "        # Wait for service to be ready\n",
    "        logger.info(f\"[{monitor_name}] Waiting for {service_name} ready...\")\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{monitor_name}] {service_name} is ready, starting checks\")\n",
    "\n",
    "        # Periodic health checks\n",
    "        check_count = 0\n",
    "        while True:\n",
    "            await sleep(0.2)  # Check every 200ms\n",
    "            check_count += 1\n",
    "            logger.info(f\"[{monitor_name}] Health check #{check_count}: OK\")\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{monitor_name}] Stopped (performed {check_count} checks)\")\n",
    "        raise\n",
    "\n",
    "# Test health monitoring\n",
    "service_events = ServiceEvents()\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start health monitor first (it will wait)\n",
    "    tg.start_soon(health_monitor, \"TestService\", service_events)\n",
    "\n",
    "    # Start service (will signal ready)\n",
    "    status = await tg.start(monitored_service, \"TestService\", 0.15, service_events)\n",
    "    print(f\"‚úì {status}\\n\")\n",
    "\n",
    "    # Let health checks run\n",
    "    await sleep(0.5)\n",
    "\n",
    "    # Shutdown\n",
    "    print(\"\\nInitiating shutdown...\\n\")\n",
    "    service_events.shutdown.set()\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n‚úì Health monitoring complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Health monitor uses `start_soon()` (fire-and-forget) since it doesn't need initialization protocol\n",
    "- Service sets `ready` event after initialization - monitor waits for this before checking\n",
    "- `shutdown` event provides clean termination signal (alternative to cancellation for some scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from lionherd_core.libs.concurrency import Queue\n",
    "\n",
    "async def background_worker(\n",
    "    worker_id: int,\n",
    "    queue: Queue,\n",
    "    events: ServiceEvents,\n",
    ") -> None:\n",
    "    \"\"\"Background worker that processes tasks from queue.\"\"\"\n",
    "    name = f\"Worker-{worker_id}\"\n",
    "    \n",
    "    try:\n",
    "        # Wait for service ready\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{name}] Started\")\n",
    "        \n",
    "        # Process tasks\n",
    "        async for task in queue:\n",
    "            logger.info(f\"[{name}] Processing task: {task}\")\n",
    "            await sleep(0.1)  # Simulate work\n",
    "            logger.info(f\"[{name}] Completed task: {task}\")\n",
    "            \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down\")\n",
    "        raise\n",
    "\n",
    "async def service_with_workers(\n",
    "    task_queue: Queue,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Service that produces tasks for workers.\"\"\"\n",
    "    name = \"TaskService\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"[{name}] Initializing...\")\n",
    "        await sleep(0.1)\n",
    "        \n",
    "        status.state = ServiceState.RUNNING\n",
    "        task_status.started(status)\n",
    "        events.ready.set()\n",
    "        logger.info(f\"[{name}] Ready\")\n",
    "        \n",
    "        # Produce tasks\n",
    "        for i in range(5):\n",
    "            await sleep(0.15)\n",
    "            await task_queue.put(f\"task-{i}\")\n",
    "            logger.info(f\"[{name}] Enqueued task-{i}\")\n",
    "        \n",
    "        # Wait for shutdown\n",
    "        await events.shutdown.wait()\n",
    "        \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        raise\n",
    "\n",
    "# Test service with background workers\n",
    "task_queue = Queue[str](max_size=10)\n",
    "worker_events = ServiceEvents()\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start workers (they wait for ready event)\n",
    "    for i in range(2):\n",
    "        tg.start_soon(background_worker, i, task_queue, worker_events)\n",
    "    \n",
    "    # Start service (signals ready, produces tasks)\n",
    "    status = await tg.start(service_with_workers, task_queue, worker_events)\n",
    "    print(f\"‚úì {status}\\n\")\n",
    "    \n",
    "    # Let workers process\n",
    "    await sleep(1.0)\n",
    "    \n",
    "    # Shutdown\n",
    "    print(\"\\nInitiating shutdown...\\n\")\n",
    "    worker_events.shutdown.set()\n",
    "    await task_queue.close()\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n‚úì Workers shutdown complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Workers use `while True: task = await queue.get()` pattern to process tasks\n",
    "- `await queue.close()` signals queue closure - `queue.get()` raises `anyio.EndOfStream`\n",
    "- Catch `anyio.EndOfStream` for graceful worker shutdown when queue closes\n",
    "- Workers wait for `ready` event before processing - ensures service is initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Working Example\n",
    "\n",
    "Here's the full production-ready implementation combining all patterns: multi-service dependencies, health monitoring, background workers, and coordinated lifecycle management.\n",
    "\n",
    "**Features**:\n",
    "- ‚úÖ Multi-component initialization (Database ‚Üí Cache ‚Üí API)\n",
    "- ‚úÖ Dependency ordering with `task_status.started()`\n",
    "- ‚úÖ Health monitoring with event coordination\n",
    "- ‚úÖ Background workers with queue processing\n",
    "- ‚úÖ Graceful shutdown with cleanup\n",
    "- ‚úÖ Production-ready error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:26:09.243] __main__: [Database] Initializing connection pool...\n",
      "[23:26:09.445] __main__: [Database] Ready\n",
      "[23:26:09.445] __main__: ‚úì Database initialized\n",
      "[23:26:09.446] __main__: [Cache] Connecting to Database...\n",
      "[23:26:09.598] __main__: [Cache] Ready\n",
      "[23:26:09.599] __main__: ‚úì Cache initialized\n",
      "[23:26:09.600] __main__: [HTTP-Server] Starting on port 8000...\n",
      "[23:26:09.702] __main__: [HTTP-Server] Ready\n",
      "[23:26:09.703] __main__: ‚úì HTTP-Server initialized on port 8000\n",
      "[23:26:09.704] __main__: \n",
      "============================================================\n",
      "[23:26:09.704] __main__: ALL SERVICES READY\n",
      "[23:26:09.705] __main__: ============================================================\n",
      "\n",
      "[23:26:09.706] __main__: [Worker-0] Started\n",
      "[23:26:09.706] __main__: [Worker-1] Started\n",
      "[23:26:09.707] __main__: [HealthMonitor(Database)] Started monitoring\n",
      "[23:26:09.707] __main__: [HealthMonitor(Cache)] Started monitoring\n",
      "[23:26:09.708] __main__: [HealthMonitor(API)] Started monitoring\n",
      "[23:26:09.903] __main__: [HTTP-Server] Enqueued request 0\n",
      "[23:26:09.904] __main__: [Worker-0] Processing: http-request-0\n",
      "[23:26:10.009] __main__: [HealthMonitor(Database)] Check #1: OK\n",
      "[23:26:10.009] __main__: [HealthMonitor(Cache)] Check #1: OK\n",
      "[23:26:10.010] __main__: [HealthMonitor(API)] Check #1: OK\n",
      "[23:26:10.056] __main__: [Worker-0] Completed: http-request-0\n",
      "[23:26:10.105] __main__: [HTTP-Server] Enqueued request 1\n",
      "[23:26:10.105] __main__: [Worker-1] Processing: http-request-1\n",
      "[23:26:10.257] __main__: [Worker-1] Completed: http-request-1\n",
      "[23:26:10.306] __main__: [HTTP-Server] Enqueued request 2\n",
      "[23:26:10.307] __main__: [Worker-0] Processing: http-request-2\n",
      "[23:26:10.310] __main__: [HealthMonitor(Database)] Check #2: OK\n",
      "[23:26:10.310] __main__: [HealthMonitor(Cache)] Check #2: OK\n",
      "[23:26:10.311] __main__: [HealthMonitor(API)] Check #2: OK\n",
      "[23:26:10.458] __main__: [Worker-0] Completed: http-request-2\n",
      "[23:26:10.611] __main__: [HealthMonitor(Database)] Check #3: OK\n",
      "[23:26:10.613] __main__: [HealthMonitor(Cache)] Check #3: OK\n",
      "[23:26:10.613] __main__: [HealthMonitor(API)] Check #3: OK\n",
      "[23:26:10.914] __main__: [HealthMonitor(Database)] Check #4: OK\n",
      "[23:26:10.915] __main__: [HealthMonitor(Cache)] Check #4: OK\n",
      "[23:26:10.916] __main__: [HealthMonitor(API)] Check #4: OK\n",
      "[23:26:11.206] __main__: \n",
      "============================================================\n",
      "[23:26:11.208] __main__: INITIATING GRACEFUL SHUTDOWN\n",
      "[23:26:11.208] __main__: ============================================================\n",
      "\n",
      "[23:26:11.209] __main__: [Worker-1] Queue closed, shutting down\n",
      "[23:26:11.212] __main__: [Worker-0] Queue closed, shutting down\n",
      "[23:26:11.215] __main__: [HealthMonitor(Database)] Check #5: OK\n",
      "[23:26:11.216] __main__: [HealthMonitor(Cache)] Check #5: OK\n",
      "[23:26:11.217] __main__: [HealthMonitor(API)] Check #5: OK\n",
      "[23:26:11.311] __main__: [HealthMonitor(Cache)] Stopped (5 checks)\n",
      "[23:26:11.311] __main__: [HealthMonitor(API)] Stopped (5 checks)\n",
      "[23:26:11.312] __main__: [HealthMonitor(Database)] Stopped (5 checks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úì COMPLETE SERVICE LIFECYCLE FINISHED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete production-ready service lifecycle manager.\n",
    "\n",
    "Demonstrates multi-component service orchestration with:\n",
    "- Coordinated initialization (dependency ordering)\n",
    "- Health monitoring (event signaling)\n",
    "- Background workers (queue processing)\n",
    "- Graceful shutdown (cleanup protocols)\n",
    "\"\"\"\n",
    "\n",
    "# Standard library\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from typing import Any\n",
    "\n",
    "# Third-party\n",
    "import anyio\n",
    "from anyio.abc import TaskStatus\n",
    "\n",
    "# lionherd-core\n",
    "from lionherd_core.libs.concurrency import (\n",
    "    Event,\n",
    "    Queue,\n",
    "    create_task_group,\n",
    "    sleep,\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s.%(msecs)03d] %(name)s: %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ServiceState(Enum):\n",
    "    INITIALIZING = \"initializing\"\n",
    "    RUNNING = \"running\"\n",
    "    STOPPING = \"stopping\"\n",
    "    STOPPED = \"stopped\"\n",
    "\n",
    "@dataclass\n",
    "class ServiceStatus:\n",
    "    name: str\n",
    "    state: ServiceState\n",
    "    details: dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class ServiceEvents:\n",
    "    ready: Event = field(default_factory=Event)\n",
    "    shutdown: Event = field(default_factory=Event)\n",
    "\n",
    "# Services\n",
    "async def database_service(\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    name = \"Database\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"[{name}] Initializing connection pool...\")\n",
    "        await sleep(0.2)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"connections\"] = 10\n",
    "        task_status.started(status)\n",
    "        events.ready.set()\n",
    "        logger.info(f\"[{name}] Ready\")\n",
    "\n",
    "        await events.shutdown.wait()\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.1)\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "async def cache_service(\n",
    "    db_status: ServiceStatus,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    name = \"Cache\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"[{name}] Connecting to {db_status.name}...\")\n",
    "        await sleep(0.15)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        task_status.started(status)\n",
    "        events.ready.set()\n",
    "        logger.info(f\"[{name}] Ready\")\n",
    "\n",
    "        await events.shutdown.wait()\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "async def http_server(\n",
    "    db_status: ServiceStatus,\n",
    "    cache_status: ServiceStatus,\n",
    "    task_queue: Queue,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    name = \"HTTP-Server\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"[{name}] Starting on port 8000...\")\n",
    "        await sleep(0.1)\n",
    "\n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"port\"] = 8000\n",
    "        task_status.started(status)\n",
    "        events.ready.set()\n",
    "        logger.info(f\"[{name}] Ready\")\n",
    "\n",
    "        # Simulate handling requests (produce tasks)\n",
    "        for i in range(3):\n",
    "            await sleep(0.2)\n",
    "            await task_queue.put(f\"http-request-{i}\")\n",
    "            logger.info(f\"[{name}] Enqueued request {i}\")\n",
    "\n",
    "        await events.shutdown.wait()\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "# Background worker\n",
    "async def background_worker(\n",
    "    worker_id: int,\n",
    "    queue: Queue,\n",
    "    events: ServiceEvents,\n",
    ") -> None:\n",
    "    name = f\"Worker-{worker_id}\"\n",
    "\n",
    "    try:\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{name}] Started\")\n",
    "\n",
    "        # Process tasks from queue\n",
    "        while True:\n",
    "            task = await queue.get()\n",
    "            logger.info(f\"[{name}] Processing: {task}\")\n",
    "            await sleep(0.15)\n",
    "            logger.info(f\"[{name}] Completed: {task}\")\n",
    "\n",
    "    except anyio.EndOfStream:\n",
    "        # Queue closed - graceful shutdown\n",
    "        logger.info(f\"[{name}] Queue closed, shutting down\")\n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Cancelled\")\n",
    "        raise\n",
    "\n",
    "# Health monitor\n",
    "async def health_monitor(service_name: str, events: ServiceEvents) -> None:\n",
    "    name = f\"HealthMonitor({service_name})\"\n",
    "\n",
    "    try:\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{name}] Started monitoring\")\n",
    "\n",
    "        check_count = 0\n",
    "        while True:\n",
    "            await sleep(0.3)\n",
    "            check_count += 1\n",
    "            logger.info(f\"[{name}] Check #{check_count}: OK\")\n",
    "\n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Stopped ({check_count} checks)\")\n",
    "        raise\n",
    "\n",
    "# Service Manager\n",
    "class ServiceManager:\n",
    "    \"\"\"Production service lifecycle manager.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.db_events = ServiceEvents()\n",
    "        self.cache_events = ServiceEvents()\n",
    "        self.api_events = ServiceEvents()\n",
    "        self.task_queue = Queue.with_maxsize(20)\n",
    "\n",
    "    async def run(self, duration: float = 2.0) -> None:\n",
    "        \"\"\"Run all services for specified duration.\"\"\"\n",
    "        async with create_task_group() as tg:\n",
    "            # Start infrastructure services in order\n",
    "            db_status = await tg.start(database_service, self.db_events)\n",
    "            logger.info(f\"‚úì {db_status.name} initialized\")\n",
    "\n",
    "            cache_status = await tg.start(\n",
    "                cache_service, db_status, self.cache_events\n",
    "            )\n",
    "            logger.info(f\"‚úì {cache_status.name} initialized\")\n",
    "\n",
    "            # Start HTTP server\n",
    "            api_status = await tg.start(\n",
    "                http_server,\n",
    "                db_status,\n",
    "                cache_status,\n",
    "                self.task_queue,\n",
    "                self.api_events,\n",
    "            )\n",
    "            logger.info(f\"‚úì {api_status.name} initialized on port {api_status.details['port']}\")\n",
    "\n",
    "            # Start background workers\n",
    "            for i in range(2):\n",
    "                tg.start_soon(\n",
    "                    background_worker, i, self.task_queue, self.api_events\n",
    "                )\n",
    "\n",
    "            # Start health monitors\n",
    "            tg.start_soon(health_monitor, \"Database\", self.db_events)\n",
    "            tg.start_soon(health_monitor, \"Cache\", self.cache_events)\n",
    "            tg.start_soon(health_monitor, \"API\", self.api_events)\n",
    "\n",
    "            logger.info(\"\\n\" + \"=\"*60)\n",
    "            logger.info(\"ALL SERVICES READY\")\n",
    "            logger.info(\"=\"*60 + \"\\n\")\n",
    "\n",
    "            # Run for specified duration\n",
    "            await sleep(duration)\n",
    "\n",
    "            # Graceful shutdown\n",
    "            logger.info(\"\\n\" + \"=\"*60)\n",
    "            logger.info(\"INITIATING GRACEFUL SHUTDOWN\")\n",
    "            logger.info(\"=\"*60 + \"\\n\")\n",
    "\n",
    "            # Signal all services to shutdown\n",
    "            self.db_events.shutdown.set()\n",
    "            self.cache_events.shutdown.set()\n",
    "            self.api_events.shutdown.set()\n",
    "\n",
    "            # Close queue (workers will finish and exit)\n",
    "            await self.task_queue.close()\n",
    "\n",
    "            # Cancel remaining tasks (monitors)\n",
    "            await sleep(0.1)\n",
    "            tg.cancel_scope.cancel()\n",
    "\n",
    "# Run the complete service manager\n",
    "manager = ServiceManager()\n",
    "await manager.run(duration=1.5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì COMPLETE SERVICE LIFECYCLE FINISHED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation: Parallel Service Initialization\n",
    "\n",
    "**When to Use**: Services have no dependencies and can initialize concurrently (faster startup)\n",
    "\n",
    "**Pattern**:\n",
    "```python\n",
    "async def parallel_startup():\n",
    "    \"\"\"Start independent services in parallel.\"\"\"\n",
    "    async with create_task_group() as tg:\n",
    "        # All start concurrently\n",
    "        db_task = tg.start(database_service, events_db)\n",
    "        metrics_task = tg.start(metrics_service, events_metrics)\n",
    "        logger_task = tg.start(logger_service, events_logger)\n",
    "        \n",
    "        # Wait for all\n",
    "        db_status = await db_task\n",
    "        metrics_status = await metrics_task\n",
    "        logger_status = await logger_task\n",
    "        \n",
    "        # Now start dependent services\n",
    "        await tg.start(api_service, db_status, events_api)\n",
    "```\n",
    "\n",
    "**Trade-offs**:\n",
    "- ‚úÖ Faster startup (services initialize concurrently)\n",
    "- ‚úÖ Better resource utilization during initialization\n",
    "- ‚ùå More complex (need to track which services are independent)\n",
    "- ‚ùå Harder to debug (concurrent failures)\n",
    "\n",
    "For additional variations (Service Registry, Phased Shutdown), see [lionherd-core examples](https://github.com/khive-ai/lionherd-core/examples/service_lifecycle_patterns.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What You Accomplished**:\n",
    "- ‚úÖ Built multi-component service manager with coordinated initialization\n",
    "- ‚úÖ Implemented dependency ordering using `task_status.started()` protocol\n",
    "- ‚úÖ Integrated health monitoring with Event-based coordination\n",
    "- ‚úÖ Added background workers with queue-based task processing\n",
    "- ‚úÖ Implemented graceful shutdown with cleanup protocols\n",
    "\n",
    "**Key Takeaways**:\n",
    "1. **Structured Concurrency**: TaskGroups ensure all tasks complete or cancel before exit - no orphaned tasks\n",
    "2. **Initialization Protocol**: `await tg.start()` + `task_status.started()` provides type-safe dependency ordering\n",
    "3. **Event Coordination**: Events signal between tasks without polling or sleep-based synchronization\n",
    "4. **Graceful Shutdown**: Cancellation propagates to all tasks, each handles cleanup in `except get_cancelled_exc_class()`\n",
    "5. **Production Readiness**: Error handling, monitoring, and configuration tuning are essential - not optional\n",
    "\n",
    "**When to Use This Pattern**:\n",
    "- ‚úÖ Multi-component services with dependencies (HTTP API + database + cache)\n",
    "- ‚úÖ Long-running services needing health monitoring\n",
    "- ‚úÖ Background task processing with queues\n",
    "- ‚úÖ Coordinated startup and shutdown requirements\n",
    "- ‚ùå Simple single-task operations (use asyncio.create_task instead)\n",
    "- ‚ùå Fire-and-forget tasks with no lifecycle management (use start_soon only)\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "**lionherd-core API Reference**:\n",
    "- [Task Groups](../../docs/api/libs/concurrency/task.md) - create_task_group, start, start_soon\n",
    "- [Primitives](../../docs/api/libs/concurrency/primitives.md) - Event, Queue, Lock\n",
    "- [Cancellation](../../docs/api/libs/concurrency/cancel.md) - Cancel scopes, timeouts\n",
    "\n",
    "**Reference Notebooks**:\n",
    "- [Task Groups Patterns](../references/concurrency_task.ipynb) - Overview of task group capabilities\n",
    "- [Primitives](../references/concurrency_primitives.ipynb) - Event, Queue, Lock usage\n",
    "- [Cancellation](../references/concurrency_cancel.ipynb) - Timeout and cancellation patterns\n",
    "\n",
    "**External Resources**:\n",
    "- [AnyIO Documentation: Task Groups](https://anyio.readthedocs.io/en/stable/tasks.html) - Underlying implementation\n",
    "- [Structured Concurrency (Nathaniel Smith)](https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/) - Conceptual foundation\n",
    "- [Production Service Patterns (AWS)](https://aws.amazon.com/builders-library/implementing-health-checks/) - Health monitoring best practices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lionherd-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
