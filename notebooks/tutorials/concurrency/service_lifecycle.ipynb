{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Service Lifecycle Management with TaskGroups\n",
    "\n",
    "**Category**: Concurrency\n",
    "**Difficulty**: Advanced\n",
    "**Time**: 25-35 minutes\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Building production services often requires coordinating multiple components with complex dependencies. Consider an HTTP API service that needs:\n",
    "\n",
    "- A database connection pool that must be ready before anything else\n",
    "- A cache layer that depends on the database\n",
    "- An HTTP server that depends on both database and cache\n",
    "- Background workers processing tasks from a queue\n",
    "- A health monitoring system that checks all components\n",
    "\n",
    "The challenge isn't just running these concurrently - it's managing their lifecycle: **initialization order**, **readiness signaling**, **health monitoring**, and **graceful shutdown**. If the database takes 2 seconds to connect, the API shouldn't start serving requests. If a component fails health checks, the service should shut down cleanly.\n",
    "\n",
    "Traditional approaches like spawning independent tasks lead to race conditions: the API starts before the database is ready, health checks run before components initialize, or shutdown leaves orphaned background workers.\n",
    "\n",
    "**Why This Matters**:\n",
    "- **Correctness**: Components accessing uninitialized dependencies cause crashes or data corruption\n",
    "- **Observability**: Without coordinated health checks, you can't tell if the service is actually ready\n",
    "- **Reliability**: Uncoordinated shutdown leaves connections open, jobs incomplete, or resources leaked\n",
    "\n",
    "**What You'll Build**:\n",
    "A production-ready service manager using lionherd-core's `create_task_group()`, `task_status.started()`, and Event coordination that manages multi-component initialization, dependency ordering, health monitoring, and graceful shutdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Prior Knowledge**:\n",
    "- Python async/await fundamentals (asyncio basics)\n",
    "- Understanding of context managers (async with)\n",
    "- Structured concurrency concepts (task groups, cancellation)\n",
    "\n",
    "**Required Packages**:\n",
    "```bash\n",
    "pip install lionherd-core  # >=1.0.0a3\n",
    "```\n",
    "\n",
    "**Optional Reading**:\n",
    "- [API Reference: Task Groups](../../docs/api/libs/concurrency/task.md)\n",
    "- [Reference Notebook: Task Groups](../references/concurrency_task.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "import logging\n",
    "\n",
    "# Third-party\n",
    "import anyio\n",
    "from anyio.abc import TaskStatus\n",
    "\n",
    "# lionherd-core\n",
    "from lionherd_core.libs.concurrency import (\n",
    "    create_task_group,\n",
    "    sleep,\n",
    "    current_time,\n",
    "    Event,\n",
    "    get_cancelled_exc_class,\n",
    ")\n",
    "\n",
    "# Configure logging for examples\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s.%(msecs)03d] %(name)s: %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Overview\n",
    "\n",
    "We'll implement a service manager using structured concurrency that handles the complete lifecycle:\n",
    "\n",
    "1. **Initialization Protocol**: Services signal readiness via `task_status.started()`\n",
    "2. **Dependency Ordering**: Parent waits for dependencies before starting dependents\n",
    "3. **Event Coordination**: Health checks use Events to signal between components\n",
    "4. **Graceful Shutdown**: Cancel scope triggers coordinated cleanup\n",
    "\n",
    "**Key lionherd-core Components**:\n",
    "- `create_task_group()`: Structured concurrency context ensuring all tasks complete\n",
    "- `TaskGroup.start()`: Wait for service initialization\n",
    "- `TaskGroup.start_soon()`: Spawn background tasks\n",
    "- `Event`: Signal coordination between tasks\n",
    "- `cancel_scope`: Timeout and graceful shutdown\n",
    "\n",
    "**Flow**:\n",
    "```\n",
    "Startup:\n",
    "  Database \u2192 started() \u2192 Cache \u2192 started() \u2192 API \u2192 started()\n",
    "                                    \u2193\n",
    "                         Health Monitor (Events)\n",
    "                                    \u2193\n",
    "                              Workers (Queue)\n",
    "\n",
    "Shutdown:\n",
    "  cancel_scope.cancel() \u2192 All tasks receive cancellation\n",
    "                       \u2192 Graceful cleanup in each\n",
    "                       \u2192 TaskGroup waits for all\n",
    "                       \u2192 Exit\n",
    "```\n",
    "\n",
    "**Expected Outcome**: Services start in correct order, health monitoring confirms readiness, shutdown is clean and coordinated."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Quick Start: Service Lifecycle in 30 Seconds\n",
    "\n",
    "from lionherd_core.libs.concurrency import create_task_group, sleep, Event\n",
    "from anyio.abc import TaskStatus\n",
    "import anyio\n",
    "\n",
    "async def service(name: str, events: Event, *, task_status: TaskStatus = anyio.TASK_STATUS_IGNORED):\n",
    "    \"\"\"Minimal service with lifecycle.\"\"\"\n",
    "    print(f\"[{name}] Starting...\")\n",
    "    await sleep(0.1)  # Simulate startup\n",
    "    \n",
    "    task_status.started(f\"{name} ready\")\n",
    "    events.set()  # Signal ready\n",
    "    print(f\"[{name}] Running\")\n",
    "    \n",
    "    await events.wait()  # Wait for shutdown\n",
    "    print(f\"[{name}] Stopped\")\n",
    "\n",
    "# Try it:\n",
    "shutdown = Event()\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start service and wait for ready\n",
    "    status = await tg.start(service, \"Database\", shutdown)\n",
    "    print(f\"\u2713 {status}\")\n",
    "    \n",
    "    await sleep(0.2)\n",
    "    \n",
    "    # Trigger shutdown\n",
    "    shutdown.set()\n",
    "\n",
    "print(\"\u2713 Lifecycle complete\")\n",
    "\n",
    "# \ud83d\udc47 Now read below to understand coordinated multi-service lifecycles"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define Service States and Event Coordination\n",
    "\n",
    "Before implementing services, we need clear state definitions and event signaling mechanisms. Services transition through states (Initializing \u2192 Running \u2192 Stopping \u2192 Stopped), and components coordinate via Events.\n",
    "\n",
    "**Why Events**: Events provide thread-safe signaling between tasks. A health monitor can wait for a \"database_ready\" event before checking database health, avoiding race conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServiceState(Enum):\n",
    "    \"\"\"Service lifecycle states.\"\"\"\n",
    "    INITIALIZING = \"initializing\"\n",
    "    RUNNING = \"running\"\n",
    "    STOPPING = \"stopping\"\n",
    "    STOPPED = \"stopped\"\n",
    "    FAILED = \"failed\"\n",
    "\n",
    "@dataclass\n",
    "class ServiceStatus:\n",
    "    \"\"\"Service status with state and metadata.\"\"\"\n",
    "    name: str\n",
    "    state: ServiceState\n",
    "    details: dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.name}: {self.state.value}\"\n",
    "\n",
    "@dataclass\n",
    "class ServiceEvents:\n",
    "    \"\"\"Coordination events for service lifecycle.\"\"\"\n",
    "    ready: Event = field(default_factory=Event)\n",
    "    shutdown: Event = field(default_factory=Event)\n",
    "    health_check: Event = field(default_factory=Event)\n",
    "\n",
    "# Example usage\n",
    "status = ServiceStatus(name=\"Database\", state=ServiceState.INITIALIZING)\n",
    "events = ServiceEvents()\n",
    "\n",
    "print(f\"Status: {status}\")\n",
    "print(f\"Events ready: {events.ready.is_set()}\")\n",
    "print(f\"Events shutdown: {events.shutdown.is_set()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- `ServiceState` enum ensures type safety and clear transitions\n",
    "- `ServiceEvents` groups related events (ready, shutdown, health_check) for easier management\n",
    "- Events are created once and shared across tasks - don't create new Event instances for coordination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Basic Service with Lifecycle\n",
    "\n",
    "A service needs initialization, operation, and cleanup phases. The `task_status.started()` protocol signals when initialization completes, allowing dependents to proceed.\n",
    "\n",
    "**Why task_status.started()**: Without it, parent tasks can't distinguish \"still initializing\" from \"ready\". Using `start()` instead of `start_soon()` provides synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def database_service(\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Simulated database service with lifecycle management.\"\"\"\n",
    "    name = \"Database\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "    \n",
    "    try:\n",
    "        # Initialize (simulate connection pool setup)\n",
    "        logger.info(f\"[{name}] Initializing connection pool...\")\n",
    "        await sleep(0.2)  # Simulate startup time\n",
    "        \n",
    "        # Signal ready\n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"connections\"] = 10\n",
    "        task_status.started(status)\n",
    "        logger.info(f\"[{name}] Ready (10 connections)\")\n",
    "        \n",
    "        # Run (keep-alive, health checks)\n",
    "        while True:\n",
    "            await sleep(1.0)  # Simulate periodic maintenance\n",
    "            \n",
    "    except get_cancelled_exc_class():\n",
    "        # Graceful shutdown\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.1)  # Simulate cleanup (close connections)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        status.state = ServiceState.FAILED\n",
    "        logger.error(f\"[{name}] Failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Test the service lifecycle\n",
    "async with create_task_group() as tg:\n",
    "    # Wait for database to initialize\n",
    "    status = await tg.start(database_service)\n",
    "    print(f\"\\n\u2713 Service started: {status}\")\n",
    "    print(f\"  Details: {status.details}\")\n",
    "    \n",
    "    # Let it run briefly\n",
    "    await sleep(0.3)\n",
    "    \n",
    "    # Trigger shutdown\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n\u2713 Service lifecycle complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- `task_status.started(status)` returns ServiceStatus to caller - useful for passing connection info\n",
    "- Cancellation triggers graceful shutdown - always catch `get_cancelled_exc_class()` for cleanup\n",
    "- State transitions (INITIALIZING \u2192 RUNNING \u2192 STOPPING \u2192 STOPPED) provide observability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add Multi-Service Coordination with Dependencies\n",
    "\n",
    "Real services have dependencies: cache needs database, API needs both. We use `await tg.start()` sequentially to enforce ordering.\n",
    "\n",
    "**Why Sequential start()**: Each `await tg.start()` blocks until `task_status.started()` is called, ensuring dependencies are ready before dependents start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cache_service(\n",
    "    db_status: ServiceStatus,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Cache service that depends on database.\"\"\"\n",
    "    name = \"Cache\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "    \n",
    "    try:\n",
    "        # Use database connection from db_status\n",
    "        logger.info(f\"[{name}] Connecting to {db_status.name}...\")\n",
    "        await sleep(0.15)\n",
    "        \n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"cache_size\"] = \"100MB\"\n",
    "        task_status.started(status)\n",
    "        logger.info(f\"[{name}] Ready (cache_size: 100MB)\")\n",
    "        \n",
    "        while True:\n",
    "            await sleep(1.0)\n",
    "            \n",
    "    except get_cancelled_exc_class():\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "async def api_service(\n",
    "    db_status: ServiceStatus,\n",
    "    cache_status: ServiceStatus,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"HTTP API service that depends on database and cache.\"\"\"\n",
    "    name = \"API\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"[{name}] Starting HTTP server (port: 8000)...\")\n",
    "        await sleep(0.1)\n",
    "        \n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"port\"] = 8000\n",
    "        status.details[\"dependencies\"] = [db_status.name, cache_status.name]\n",
    "        task_status.started(status)\n",
    "        logger.info(f\"[{name}] Ready (port: 8000)\")\n",
    "        \n",
    "        while True:\n",
    "            await sleep(1.0)\n",
    "            \n",
    "    except get_cancelled_exc_class():\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "# Test coordinated startup\n",
    "async with create_task_group() as tg:\n",
    "    # Start in dependency order\n",
    "    db_status = await tg.start(database_service)\n",
    "    print(f\"\u2713 {db_status}\")\n",
    "    \n",
    "    cache_status = await tg.start(cache_service, db_status)\n",
    "    print(f\"\u2713 {cache_status}\")\n",
    "    \n",
    "    api_status = await tg.start(api_service, db_status, cache_status)\n",
    "    print(f\"\u2713 {api_status}\")\n",
    "    print(f\"  Dependencies: {api_status.details['dependencies']}\")\n",
    "    \n",
    "    # All services running\n",
    "    print(\"\\n\u2713 All services ready\\n\")\n",
    "    await sleep(0.3)\n",
    "    \n",
    "    # Coordinated shutdown\n",
    "    print(\"Initiating shutdown...\\n\")\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n\u2713 Coordinated lifecycle complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Passing `db_status` to `cache_service` provides connection info (not just signaling)\n",
    "- Services start sequentially but run concurrently after initialization\n",
    "- Shutdown happens in reverse (cancel propagates to all tasks simultaneously)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Add Health Monitoring with Event Signaling\n",
    "\n",
    "Health monitors need to coordinate with services: wait for services to be ready, check them periodically, signal failures.\n",
    "\n",
    "**Why Events**: Health monitor waits for `ready` event before checking. Services set events after initialization. This avoids polling or sleep-based coordination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def monitored_service(\n",
    "    name: str,\n",
    "    startup_time: float,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Service with health monitoring integration.\"\"\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"[{name}] Initializing...\")\n",
    "        await sleep(startup_time)\n",
    "        \n",
    "        status.state = ServiceState.RUNNING\n",
    "        task_status.started(status)\n",
    "        events.ready.set()  # Signal health monitor\n",
    "        logger.info(f\"[{name}] Ready (ready event set)\")\n",
    "        \n",
    "        # Wait for shutdown signal\n",
    "        await events.shutdown.wait()\n",
    "        \n",
    "    except get_cancelled_exc_class():\n",
    "        status.state = ServiceState.STOPPING\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        status.state = ServiceState.STOPPED\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "async def health_monitor(\n",
    "    service_name: str,\n",
    "    events: ServiceEvents,\n",
    ") -> None:\n",
    "    \"\"\"Health monitoring task that waits for service readiness.\"\"\"\n",
    "    monitor_name = f\"HealthMonitor({service_name})\"\n",
    "    \n",
    "    try:\n",
    "        # Wait for service to be ready\n",
    "        logger.info(f\"[{monitor_name}] Waiting for {service_name} ready...\")\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{monitor_name}] {service_name} is ready, starting checks\")\n",
    "        \n",
    "        # Periodic health checks\n",
    "        check_count = 0\n",
    "        while True:\n",
    "            await sleep(0.2)  # Check every 200ms\n",
    "            check_count += 1\n",
    "            logger.info(f\"[{monitor_name}] Health check #{check_count}: OK\")\n",
    "            \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{monitor_name}] Stopped (performed {check_count} checks)\")\n",
    "        raise\n",
    "\n",
    "# Test health monitoring\n",
    "service_events = ServiceEvents()\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start health monitor first (it will wait)\n",
    "    tg.start_soon(health_monitor, \"TestService\", service_events)\n",
    "    \n",
    "    # Start service (will signal ready)\n",
    "    status = await tg.start(monitored_service, \"TestService\", 0.15, service_events)\n",
    "    print(f\"\u2713 {status}\\n\")\n",
    "    \n",
    "    # Let health checks run\n",
    "    await sleep(0.5)\n",
    "    \n",
    "    # Shutdown\n",
    "    print(\"\\nInitiating shutdown...\\n\")\n",
    "    service_events.shutdown.set()\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n\u2713 Health monitoring complete\")",
    "\n\n",
    "**Notes**:\n",
    "- Health monitor uses `start_soon()` (fire-and-forget) since it doesn't need initialization protocol\n",
    "- Service sets `ready` event after initialization - monitor waits for this before checking\n",
    "- `shutdown` event provides clean termination signal (alternative to cancellation for some scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Add Background Workers with Queue Processing\n",
    "\n",
    "Background workers process tasks from a queue. They need to coordinate with the main service: start after service is ready, shutdown gracefully when service stops.\n",
    "\n",
    "**Why Queue Pattern**: Workers pull tasks from queue, avoiding direct coupling. Service can add tasks, workers process independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lionherd_core.libs.concurrency import Queue\n",
    "\n",
    "async def background_worker(\n",
    "    worker_id: int,\n",
    "    queue: Queue,\n",
    "    events: ServiceEvents,\n",
    ") -> None:\n",
    "    \"\"\"Background worker that processes tasks from queue.\"\"\"\n",
    "    name = f\"Worker-{worker_id}\"\n",
    "    \n",
    "    try:\n",
    "        # Wait for service ready\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{name}] Started\")\n",
    "        \n",
    "        # Process tasks\n",
    "        async for task in queue:\n",
    "            logger.info(f\"[{name}] Processing task: {task}\")\n",
    "            await sleep(0.1)  # Simulate work\n",
    "            logger.info(f\"[{name}] Completed task: {task}\")\n",
    "            \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down\")\n",
    "        raise\n",
    "\n",
    "async def service_with_workers(\n",
    "    task_queue: Queue,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    \"\"\"Service that produces tasks for workers.\"\"\"\n",
    "    name = \"TaskService\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"[{name}] Initializing...\")\n",
    "        await sleep(0.1)\n",
    "        \n",
    "        status.state = ServiceState.RUNNING\n",
    "        task_status.started(status)\n",
    "        events.ready.set()\n",
    "        logger.info(f\"[{name}] Ready\")\n",
    "        \n",
    "        # Produce tasks\n",
    "        for i in range(5):\n",
    "            await sleep(0.15)\n",
    "            await task_queue.put(f\"task-{i}\")\n",
    "            logger.info(f\"[{name}] Enqueued task-{i}\")\n",
    "        \n",
    "        # Wait for shutdown\n",
    "        await events.shutdown.wait()\n",
    "        \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        raise\n",
    "\n",
    "# Test service with background workers\n",
    "task_queue = Queue[str](max_size=10)\n",
    "worker_events = ServiceEvents()\n",
    "\n",
    "async with create_task_group() as tg:\n",
    "    # Start workers (they wait for ready event)\n",
    "    for i in range(2):\n",
    "        tg.start_soon(background_worker, i, task_queue, worker_events)\n",
    "    \n",
    "    # Start service (signals ready, produces tasks)\n",
    "    status = await tg.start(service_with_workers, task_queue, worker_events)\n",
    "    print(f\"\u2713 {status}\\n\")\n",
    "    \n",
    "    # Let workers process\n",
    "    await sleep(1.0)\n",
    "    \n",
    "    # Shutdown\n",
    "    print(\"\\nInitiating shutdown...\\n\")\n",
    "    worker_events.shutdown.set()\n",
    "    await task_queue.close()\n",
    "    tg.cancel_scope.cancel()\n",
    "\n",
    "print(\"\\n\u2713 Workers shutdown complete\")",
    "\n\n",
    "**Notes**:\n",
    "- Workers use `async for task in queue` - clean iteration pattern\n",
    "- `await queue.close()` signals workers to finish processing and exit\n",
    "- Workers wait for `ready` event before processing - ensures service is initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Working Example\n",
    "\n",
    "Here's the full production-ready implementation combining all patterns: multi-service dependencies, health monitoring, background workers, and coordinated lifecycle management.\n",
    "\n",
    "**Features**:\n",
    "- \u2705 Multi-component initialization (Database \u2192 Cache \u2192 API)\n",
    "- \u2705 Dependency ordering with `task_status.started()`\n",
    "- \u2705 Health monitoring with event coordination\n",
    "- \u2705 Background workers with queue processing\n",
    "- \u2705 Graceful shutdown with cleanup\n",
    "- \u2705 Production-ready error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Complete production-ready service lifecycle manager.\n",
    "\n",
    "Demonstrates multi-component service orchestration with:\n",
    "- Coordinated initialization (dependency ordering)\n",
    "- Health monitoring (event signaling)\n",
    "- Background workers (queue processing)\n",
    "- Graceful shutdown (cleanup protocols)\n",
    "\"\"\"\n",
    "\n",
    "# Standard library\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "import logging\n",
    "\n",
    "# Third-party\n",
    "import anyio\n",
    "from anyio.abc import TaskStatus\n",
    "\n",
    "# lionherd-core\n",
    "from lionherd_core.libs.concurrency import (\n",
    "    create_task_group,\n",
    "    sleep,\n",
    "    Event,\n",
    "    Queue,\n",
    "    get_cancelled_exc_class,\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s.%(msecs)03d] %(name)s: %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ServiceState(Enum):\n",
    "    INITIALIZING = \"initializing\"\n",
    "    RUNNING = \"running\"\n",
    "    STOPPING = \"stopping\"\n",
    "    STOPPED = \"stopped\"\n",
    "\n",
    "@dataclass\n",
    "class ServiceStatus:\n",
    "    name: str\n",
    "    state: ServiceState\n",
    "    details: dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class ServiceEvents:\n",
    "    ready: Event = field(default_factory=Event)\n",
    "    shutdown: Event = field(default_factory=Event)\n",
    "\n",
    "# Services\n",
    "async def database_service(\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    name = \"Database\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"[{name}] Initializing connection pool...\")\n",
    "        await sleep(0.2)\n",
    "        \n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"connections\"] = 10\n",
    "        task_status.started(status)\n",
    "        events.ready.set()\n",
    "        logger.info(f\"[{name}] Ready\")\n",
    "        \n",
    "        await events.shutdown.wait()\n",
    "        \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.1)\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "async def cache_service(\n",
    "    db_status: ServiceStatus,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    name = \"Cache\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"[{name}] Connecting to {db_status.name}...\")\n",
    "        await sleep(0.15)\n",
    "        \n",
    "        status.state = ServiceState.RUNNING\n",
    "        task_status.started(status)\n",
    "        events.ready.set()\n",
    "        logger.info(f\"[{name}] Ready\")\n",
    "        \n",
    "        await events.shutdown.wait()\n",
    "        \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "async def http_server(\n",
    "    db_status: ServiceStatus,\n",
    "    cache_status: ServiceStatus,\n",
    "    task_queue: Queue,\n",
    "    events: ServiceEvents,\n",
    "    *,\n",
    "    task_status: TaskStatus[ServiceStatus] = anyio.TASK_STATUS_IGNORED,\n",
    ") -> None:\n",
    "    name = \"HTTP-Server\"\n",
    "    status = ServiceStatus(name=name, state=ServiceState.INITIALIZING)\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"[{name}] Starting on port 8000...\")\n",
    "        await sleep(0.1)\n",
    "        \n",
    "        status.state = ServiceState.RUNNING\n",
    "        status.details[\"port\"] = 8000\n",
    "        task_status.started(status)\n",
    "        events.ready.set()\n",
    "        logger.info(f\"[{name}] Ready\")\n",
    "        \n",
    "        # Simulate handling requests (produce tasks)\n",
    "        for i in range(3):\n",
    "            await sleep(0.2)\n",
    "            await task_queue.put(f\"http-request-{i}\")\n",
    "            logger.info(f\"[{name}] Enqueued request {i}\")\n",
    "        \n",
    "        await events.shutdown.wait()\n",
    "        \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Shutting down...\")\n",
    "        await sleep(0.05)\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "# Background worker\n",
    "async def background_worker(\n",
    "    worker_id: int,\n",
    "    queue: Queue,\n",
    "    events: ServiceEvents,\n",
    ") -> None:\n",
    "    name = f\"Worker-{worker_id}\"\n",
    "    \n",
    "    try:\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{name}] Started\")\n",
    "        \n",
    "        async for task in queue:\n",
    "            logger.info(f\"[{name}] Processing: {task}\")\n",
    "            await sleep(0.15)\n",
    "            logger.info(f\"[{name}] Completed: {task}\")\n",
    "            \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Stopped\")\n",
    "        raise\n",
    "\n",
    "# Health monitor\n",
    "async def health_monitor(service_name: str, events: ServiceEvents) -> None:\n",
    "    name = f\"HealthMonitor({service_name})\"\n",
    "    \n",
    "    try:\n",
    "        await events.ready.wait()\n",
    "        logger.info(f\"[{name}] Started monitoring\")\n",
    "        \n",
    "        check_count = 0\n",
    "        while True:\n",
    "            await sleep(0.3)\n",
    "            check_count += 1\n",
    "            logger.info(f\"[{name}] Check #{check_count}: OK\")\n",
    "            \n",
    "    except get_cancelled_exc_class():\n",
    "        logger.info(f\"[{name}] Stopped ({check_count} checks)\")\n",
    "        raise\n",
    "\n",
    "# Service Manager\n",
    "class ServiceManager:\n",
    "    \"\"\"Production service lifecycle manager.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.db_events = ServiceEvents()\n",
    "        self.cache_events = ServiceEvents()\n",
    "        self.api_events = ServiceEvents()\n",
    "        self.task_queue = Queue[str](max_size=20)\n",
    "    \n",
    "    async def run(self, duration: float = 2.0) -> None:\n",
    "        \"\"\"Run all services for specified duration.\"\"\"\n",
    "        async with create_task_group() as tg:\n",
    "            # Start infrastructure services in order\n",
    "            db_status = await tg.start(database_service, self.db_events)\n",
    "            logger.info(f\"\u2713 {db_status.name} initialized\")\n",
    "            \n",
    "            cache_status = await tg.start(\n",
    "                cache_service, db_status, self.cache_events\n",
    "            )\n",
    "            logger.info(f\"\u2713 {cache_status.name} initialized\")\n",
    "            \n",
    "            # Start HTTP server\n",
    "            api_status = await tg.start(\n",
    "                http_server,\n",
    "                db_status,\n",
    "                cache_status,\n",
    "                self.task_queue,\n",
    "                self.api_events,\n",
    "            )\n",
    "            logger.info(f\"\u2713 {api_status.name} initialized on port {api_status.details['port']}\")\n",
    "            \n",
    "            # Start background workers\n",
    "            for i in range(2):\n",
    "                tg.start_soon(\n",
    "                    background_worker, i, self.task_queue, self.api_events\n",
    "                )\n",
    "            \n",
    "            # Start health monitors\n",
    "            tg.start_soon(health_monitor, \"Database\", self.db_events)\n",
    "            tg.start_soon(health_monitor, \"Cache\", self.cache_events)\n",
    "            tg.start_soon(health_monitor, \"API\", self.api_events)\n",
    "            \n",
    "            logger.info(\"\\n\" + \"=\"*60)\n",
    "            logger.info(\"ALL SERVICES READY\")\n",
    "            logger.info(\"=\"*60 + \"\\n\")\n",
    "            \n",
    "            # Run for specified duration\n",
    "            await sleep(duration)\n",
    "            \n",
    "            # Graceful shutdown\n",
    "            logger.info(\"\\n\" + \"=\"*60)\n",
    "            logger.info(\"INITIATING GRACEFUL SHUTDOWN\")\n",
    "            logger.info(\"=\"*60 + \"\\n\")\n",
    "            \n",
    "            # Signal all services to shutdown\n",
    "            self.db_events.shutdown.set()\n",
    "            self.cache_events.shutdown.set()\n",
    "            self.api_events.shutdown.set()\n",
    "            \n",
    "            # Close queue (workers will finish and exit)\n",
    "            await self.task_queue.close()\n",
    "            \n",
    "            # Cancel remaining tasks (monitors)\n",
    "            await sleep(0.1)\n",
    "            tg.cancel_scope.cancel()\n",
    "\n",
    "# Run the complete service manager\n",
    "manager = ServiceManager()\n",
    "await manager.run(duration=1.5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\u2713 COMPLETE SERVICE LIFECYCLE FINISHED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation: Parallel Service Initialization\n",
    "\n",
    "**When to Use**: Services have no dependencies and can initialize concurrently (faster startup)\n",
    "\n",
    "**Pattern**:\n",
    "```python\n",
    "async def parallel_startup():\n",
    "    \"\"\"Start independent services in parallel.\"\"\"\n",
    "    async with create_task_group() as tg:\n",
    "        # All start concurrently\n",
    "        db_task = tg.start(database_service, events_db)\n",
    "        metrics_task = tg.start(metrics_service, events_metrics)\n",
    "        logger_task = tg.start(logger_service, events_logger)\n",
    "        \n",
    "        # Wait for all\n",
    "        db_status = await db_task\n",
    "        metrics_status = await metrics_task\n",
    "        logger_status = await logger_task\n",
    "        \n",
    "        # Now start dependent services\n",
    "        await tg.start(api_service, db_status, events_api)\n",
    "```\n",
    "\n",
    "**Trade-offs**:\n",
    "- \u2705 Faster startup (services initialize concurrently)\n",
    "- \u2705 Better resource utilization during initialization\n",
    "- \u274c More complex (need to track which services are independent)\n",
    "- \u274c Harder to debug (concurrent failures)\n",
    "\n",
    "For additional variations (Service Registry, Phased Shutdown), see [lionherd-core examples](https://github.com/khive-ai/lionherd-core/examples/service_lifecycle_patterns.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What You Accomplished**:\n",
    "- \u2705 Built multi-component service manager with coordinated initialization\n",
    "- \u2705 Implemented dependency ordering using `task_status.started()` protocol\n",
    "- \u2705 Integrated health monitoring with Event-based coordination\n",
    "- \u2705 Added background workers with queue-based task processing\n",
    "- \u2705 Implemented graceful shutdown with cleanup protocols\n",
    "\n",
    "**Key Takeaways**:\n",
    "1. **Structured Concurrency**: TaskGroups ensure all tasks complete or cancel before exit - no orphaned tasks\n",
    "2. **Initialization Protocol**: `await tg.start()` + `task_status.started()` provides type-safe dependency ordering\n",
    "3. **Event Coordination**: Events signal between tasks without polling or sleep-based synchronization\n",
    "4. **Graceful Shutdown**: Cancellation propagates to all tasks, each handles cleanup in `except get_cancelled_exc_class()`\n",
    "5. **Production Readiness**: Error handling, monitoring, and configuration tuning are essential - not optional\n",
    "\n",
    "**When to Use This Pattern**:\n",
    "- \u2705 Multi-component services with dependencies (HTTP API + database + cache)\n",
    "- \u2705 Long-running services needing health monitoring\n",
    "- \u2705 Background task processing with queues\n",
    "- \u2705 Coordinated startup and shutdown requirements\n",
    "- \u274c Simple single-task operations (use asyncio.create_task instead)\n",
    "- \u274c Fire-and-forget tasks with no lifecycle management (use start_soon only)\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "**lionherd-core API Reference**:\n",
    "- [Task Groups](../../docs/api/libs/concurrency/task.md) - create_task_group, start, start_soon\n",
    "- [Primitives](../../docs/api/libs/concurrency/primitives.md) - Event, Queue, Lock\n",
    "- [Cancellation](../../docs/api/libs/concurrency/cancel.md) - Cancel scopes, timeouts\n",
    "\n",
    "**Reference Notebooks**:\n",
    "- [Task Groups Patterns](../references/concurrency_task.ipynb) - Overview of task group capabilities\n",
    "- [Primitives](../references/concurrency_primitives.ipynb) - Event, Queue, Lock usage\n",
    "- [Cancellation](../references/concurrency_cancel.ipynb) - Timeout and cancellation patterns\n",
    "\n",
    "**External Resources**:\n",
    "- [AnyIO Documentation: Task Groups](https://anyio.readthedocs.io/en/stable/tasks.html) - Underlying implementation\n",
    "- [Structured Concurrency (Nathaniel Smith)](https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/) - Conceptual foundation\n",
    "- [Production Service Patterns (AWS)](https://aws.amazon.com/builders-library/implementing-health-checks/) - Health monitoring best practices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}