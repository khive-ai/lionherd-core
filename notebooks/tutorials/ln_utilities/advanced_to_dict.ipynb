{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial: Advanced Type Conversions with to_dict()\n\n",
        "**Category**: ln Utilities\n",
        "**Difficulty**: Intermediate\n",
        "**Time**: 15-20 minutes\n\n",
        "## Problem Statement\n\n",
        "Modern AI applications work with heterogeneous data: LLM responses with JSON strings, API responses mixing Pydantic models and dicts, configurations combining dataclasses and enums. Manually normalizing this mixed-type data is error-prone.\n\n",
        "**Why This Matters**:\n",
        "- **Data Pipeline Reliability**: Mixed-type inputs cause parsing failures\n",
        "- **LLM Integration Fragility**: LLMs return JSON with trailing commas or nested as strings\n\n",
        "**What You'll Build**:\n",
        "A data normalization pipeline using lionherd-core's `to_dict()` that handles 7+ input types with recursive parsing and fuzzy JSON fallback."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n\n",
        "**Prior Knowledge**:\n",
        "- Python type system (dataclasses, enums)\n",
        "- JSON parsing basics\n\n",
        "**Required Packages**:\n",
        "```bash\n",
        "pip install lionherd-core  # >=0.1.0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library\n",
        "import json\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from typing import Any\n\n",
        "# lionherd-core\n",
        "from lionherd_core.ln import to_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution Overview\n\n",
        "We'll implement universal data normalization using `to_dict()`:\n\n",
        "1. **Basic Types**: Handle dicts, lists, sets, None\n",
        "2. **JSON Strings**: Parse JSON strings with fuzzy fallback\n",
        "3. **Structured Types**: Convert dataclasses and enums\n",
        "4. **Recursive Processing**: Deep conversion with depth control\n\n",
        "**Key lionherd-core Components**:\n",
        "- `to_dict()`: Universal conversion with recursive processing\n",
        "- Automatic JSON parsing for strings (orjson + fuzzy fallback)\n",
        "- Dataclass/enum support\n",
        "- Depth-limited recursion (max 10 levels)\n\n",
        "**Pattern**: All input types normalize to flat or nested dictionaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Basic Type Conversions and JSON Parsing\n\n",
        "Start with fundamental conversions and JSON string parsing.\n\n",
        "**Key Point**: Lists become indexed dicts `{0: val, 1: val}`, sets become value mappings `{val: val}`, None becomes `{}`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dict \u2192 dict (shallow copy)\n",
        "user_data = {\"name\": \"Alice\", \"age\": 30}\n",
        "result = to_dict(user_data)\n",
        "print(f\"Dict: {result}\\n\")\n\n",
        "# List \u2192 indexed dict\n",
        "items = [\"apple\", \"banana\"]\n",
        "result = to_dict(items)\n",
        "print(f\"List \u2192 indexed dict: {result}\\n\")\n\n",
        "# JSON string parsing\n",
        "llm_response = '{\"status\": \"success\", \"data\": {\"count\": 42}}'\n",
        "result = to_dict(llm_response)\n",
        "print(f\"Parsed JSON: {result}\\n\")\n\n",
        "# Malformed JSON with fuzzy parser\n",
        "malformed = '{\"name\": \"Bob\", \"age\": 25, }'\n",
        "result = to_dict(malformed, fuzzy_parse=True)\n",
        "print(f\"Fuzzy parsed: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Dataclass and Enum Conversion\n\n",
        "Configuration systems use dataclasses and enums. `to_dict()` automatically converts these.\n\n",
        "**Key Point**: Nested dataclasses convert recursively via `dataclasses.asdict()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataclass conversion\n",
        "@dataclass\n",
        "class ServiceConfig:\n",
        "    name: str\n",
        "    port: int\n",
        "    debug: bool = False\n\n",
        "config = ServiceConfig(name=\"api-server\", port=8000, debug=True)\n",
        "result = to_dict(config)\n",
        "print(f\"Dataclass: {result}\\n\")\n\n",
        "# Enum class\n",
        "class Environment(Enum):\n",
        "    DEV = \"development\"\n",
        "    PROD = \"production\"\n\n",
        "# Extract enum values\n",
        "result = to_dict(Environment, use_enum_values=True)\n",
        "print(f\"Enum values: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Recursive Processing for Nested Structures\n\n",
        "LLM outputs contain nested JSON strings. Recursive processing parses these at all depths.\n\n",
        "**Key Point**: Default depth limit (5 levels) prevents stack overflow while handling real data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nested JSON strings (common in LLM tool outputs)\n",
        "llm_tool_output = {\n",
        "    \"user\": '{\"name\": \"Alice\", \"age\": 30}',\n",
        "    \"nested\": {\n",
        "        \"config\": '{\"debug\": true, \"level\": 2}'\n",
        "    }\n",
        "}\n\n",
        "# Without recursion - JSON strings remain unparsed\n",
        "result_no_recurse = to_dict(llm_tool_output, recursive=False)\n",
        "print(\"Without recursion:\")\n",
        "print(f\"  user type: {type(result_no_recurse['user'])}\\n\")\n\n",
        "# With recursion - all JSON strings parsed\n",
        "result_recurse = to_dict(llm_tool_output, recursive=True)\n",
        "print(\"With recursion:\")\n",
        "print(f\"  user: {result_recurse['user']}\")\n",
        "print(f\"  nested.config: {result_recurse['nested']['config']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete Working Example\n\n",
        "Production-ready data normalization for heterogeneous inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Production data normalization pipeline.\n",
        "\"\"\"\n",
        "from typing import Any\n",
        "from dataclasses import dataclass\n",
        "from lionherd_core.ln import to_dict\n\n",
        "class DataNormalizer:\n",
        "    \"\"\"Universal data normalization with configurable recursion.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        max_depth: int = 5,\n",
        "        fuzzy_parse: bool = True,\n",
        "        suppress_errors: bool = False,\n",
        "    ):\n",
        "        self.max_depth = max_depth\n",
        "        self.fuzzy_parse = fuzzy_parse\n",
        "        self.suppress_errors = suppress_errors\n",
        "    \n",
        "    def normalize(\n",
        "        self,\n",
        "        data: Any,\n",
        "        recursive: bool = True,\n",
        "    ) -> dict[str | int, Any]:\n",
        "        \"\"\"Normalize heterogeneous input to dictionary.\"\"\"\n",
        "        return to_dict(\n",
        "            data,\n",
        "            recursive=recursive,\n",
        "            max_recursive_depth=self.max_depth,\n",
        "            recursive_python_only=False,  # Convert custom objects\n",
        "            fuzzy_parse=self.fuzzy_parse,\n",
        "            suppress=self.suppress_errors,\n",
        "            use_enum_values=True,  # Extract enum values\n",
        "        )\n\n",
        "# Example usage\n",
        "normalizer = DataNormalizer(max_depth=10, fuzzy_parse=True)\n\n",
        "# LLM output with nested JSON\n",
        "llm_output = {\n",
        "    \"tool_name\": \"analyzer\",\n",
        "    \"result\": '{\"summary\": \"Complete\", \"stats\": {\"count\": 42}}',\n",
        "}\n\n",
        "normalized = normalizer.normalize(llm_output)\n",
        "print(f\"Result: {normalized['result']['summary']}\")\n",
        "print(f\"Stats: {normalized['result']['stats']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Production Considerations\n\n",
        "### Error Handling\n\n",
        "```python\n",
        "# Fault-tolerant mode for production\n",
        "result = to_dict(data, suppress=True, fuzzy_parse=True)\n",
        "if not result:\n",
        "    logger.warning(f\"Failed to convert: {data}\")\n",
        "```\n\n",
        "### Performance\n\n",
        "- **JSON parsing**: `orjson` is O(n), ~2-3x faster than stdlib\n",
        "- **Recursive processing**: O(n \u00d7 d) where d=depth\n",
        "- **Benchmarks**: <1ms for typical API responses (<10KB)\n\n",
        "### Testing\n\n",
        "```python\n",
        "def test_recursive_processing():\n",
        "    nested = {\"outer\": '{\"inner\": {\"value\": 123}}'}\n",
        "    result = to_dict(nested, recursive=True)\n",
        "    assert result[\"outer\"][\"inner\"][\"value\"] == 123\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variations\n\n",
        "### Custom Parser\n\n",
        "```python\n",
        "import yaml\n\n",
        "def yaml_parser(s: str, **kwargs) -> dict:\n",
        "    return yaml.safe_load(s)\n\n",
        "result = to_dict(yaml_string, parser=yaml_parser)\n",
        "```\n\n",
        "### Selective Recursion\n\n",
        "```python\n",
        "def selective_normalize(data: dict, recursive_keys: set[str]):\n",
        "    result = {}\n",
        "    for key, value in data.items():\n",
        "        if key in recursive_keys:\n",
        "            result[key] = to_dict(value, recursive=True)\n",
        "        else:\n",
        "            result[key] = to_dict(value, recursive=False)\n",
        "    return result\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n\n",
        "**What You Accomplished**:\n",
        "- \u2705 Built universal data normalizer handling 7+ input types\n",
        "- \u2705 Implemented recursive JSON parsing with fuzzy fallback\n",
        "- \u2705 Configured depth control and error handling\n\n",
        "**Key Takeaways**:\n",
        "1. **Universal conversion eliminates type-checking**: `to_dict()` handles all common types\n",
        "2. **Recursive processing with depth limits**: Default depth 5 balances safety/practicality\n",
        "3. **Fuzzy parsing improves LLM integration**: ~15-20% of LLM outputs have JSON errors\n\n",
        "**When to Use**:\n",
        "- \u2705 Processing heterogeneous API responses or LLM outputs\n",
        "- \u2705 Normalizing configuration data from multiple formats\n",
        "- \u274c Simple dict conversion where `dict(obj)` suffices\n\n",
        "## Related Resources\n\n",
        "- [to_dict API](../../docs/api/ln/to_dict.md)\n",
        "- [Pydantic Documentation](https://docs.pydantic.dev/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}